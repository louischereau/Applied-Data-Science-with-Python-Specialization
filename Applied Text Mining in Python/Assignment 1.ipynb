{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment, you'll be working with messy medical data and using regex to extract relevant infromation from the data. \n",
    "\n",
    "Each line of the `dates.txt` file corresponds to a medical note. Each note has a date that needs to be extracted, but each date is encoded in one of many formats.\n",
    "\n",
    "The goal of this assignment is to correctly identify all of the different date variants encoded in this dataset and to properly normalize and sort the dates. \n",
    "\n",
    "Here is a list of some of the variants you might encounter in this dataset:\n",
    "* 04/20/2009; 04/20/09; 4/20/09; 4/3/09\n",
    "* Mar-20-2009; Mar 20, 2009; March 20, 2009;  Mar. 20, 2009; Mar 20 2009;\n",
    "* 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009\n",
    "* Mar 20th, 2009; Mar 21st, 2009; Mar 22nd, 2009\n",
    "* Feb 2009; Sep 2009; Oct 2010\n",
    "* 6/2008; 12/2009\n",
    "* 2009; 2010\n",
    "\n",
    "Once you have extracted these date patterns from the text, the next step is to sort them in ascending chronological order accoring to the following rules:\n",
    "* Assume all dates in xx/xx/xx format are mm/dd/yy\n",
    "* Assume all dates where year is encoded in only two digits are years from the 1900's (e.g. 1/5/89 is January 5th, 1989)\n",
    "* If the day is missing (e.g. 9/2009), assume it is the first day of the month (e.g. September 1, 2009).\n",
    "* If the month is missing (e.g. 2010), assume it is the first of January of that year (e.g. January 1, 2010).\n",
    "* Watch out for potential typos as this is a raw, real-life derived dataset.\n",
    "\n",
    "With these rules in mind, find the correct date in each note and return a pandas Series in chronological order of the original Series' indices.\n",
    "\n",
    "For example if the original series was this:\n",
    "\n",
    "    0    1999\n",
    "    1    2010\n",
    "    2    1978\n",
    "    3    2015\n",
    "    4    1985\n",
    "\n",
    "Your function should return this:\n",
    "\n",
    "    0    2\n",
    "    1    4\n",
    "    2    0\n",
    "    3    1\n",
    "    4    3\n",
    "\n",
    "Your score will be calculated using [Kendall's tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient), a correlation measure for ordinal data.\n",
    "\n",
    "*This function should return a Series of length 500 and dtype int.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "doc = []\n",
    "with open('dates.txt') as file:\n",
    "    for line in file:\n",
    "        doc.append(line)\n",
    "\n",
    "df = pd.DataFrame(doc, columns = ['text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        9\n",
       "1       84\n",
       "2        2\n",
       "3       53\n",
       "4       28\n",
       "5      474\n",
       "6      153\n",
       "7       13\n",
       "8      129\n",
       "9       98\n",
       "10     111\n",
       "11     225\n",
       "12      31\n",
       "13     171\n",
       "14     191\n",
       "15     486\n",
       "16     335\n",
       "17     415\n",
       "18      36\n",
       "19     405\n",
       "20     323\n",
       "21     422\n",
       "22     375\n",
       "23     380\n",
       "24     345\n",
       "25      57\n",
       "26     481\n",
       "27     436\n",
       "28     104\n",
       "29     299\n",
       "      ... \n",
       "470    220\n",
       "471    208\n",
       "472    243\n",
       "473    139\n",
       "474    320\n",
       "475    383\n",
       "476    244\n",
       "477    286\n",
       "478    480\n",
       "479    431\n",
       "480    279\n",
       "481    198\n",
       "482    381\n",
       "483    463\n",
       "484    366\n",
       "485    439\n",
       "486    255\n",
       "487    401\n",
       "488    475\n",
       "489    257\n",
       "490    152\n",
       "491    235\n",
       "492    464\n",
       "493    253\n",
       "494    427\n",
       "495    231\n",
       "496    141\n",
       "497    186\n",
       "498    161\n",
       "499    413\n",
       "Length: 500, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def date_sorter():\n",
    "\n",
    "    f1 = df['text'].str.extract(r'(?P<date>\\d{1,2}[/|-]\\d{1,2}[/|-][1,2]?\\d?\\d{2})')\n",
    "\n",
    "    f2 = df['text'].str.extract(r'(?P<date>(?:\\d{,2}\\s)?(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\W?(?:\\s\\d{,2}\\W?)?(?:\\s[1,2]\\d{3}))')\n",
    "\n",
    "    f3 = df['text'].str.extract(r'(?P<date>\\d{0,2}/?[1,2]\\d{3})')\n",
    "\n",
    "    data = pd.to_datetime(f1.fillna(f2).fillna(f3).str.replace('Decemeber','December').str.replace('Janaury','January'))\n",
    "\n",
    "    data = data.sort_values(ascending = True)\n",
    "\n",
    "    return pd.Series(data.index)\n",
    "\n",
    "date_sorter()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def date_sorter():\n",
    "    \n",
    "    month1 = {'Jan':'01','Feb':'02','Mar':'03','Apr':'04','May':'05','Jun':'06',\n",
    "                 'Jul':'07','Aug':'08','Sep':'09','Oct':'10','Nov':'11','Dec':'12'}\n",
    "    \n",
    "    month2 = {'January':'01','February':'02','March':'03','April':'04','May':'05','June':'06',\n",
    "                 'July':'07','August':'08','September':'09','October':'10','November':'11','December':'12'}\n",
    "    \n",
    "    f1 = df['text'].str.extractall(r'(?P<year>\\W[^/][12]\\d{3}\\W[^/])')\n",
    "    f1['year']= f1['year'].str.replace('[^0-9]','')\n",
    "    f1['year'] = f1['year'].apply(lambda x: x.strip())\n",
    "    f1['month'] = '01'\n",
    "    f1['day'] = '01'\n",
    "    f1['data1'] = f1['year']+'-'+f1['month']+'-'+f1['day']\n",
    "    f1 = f1.reset_index(level=[0,1]).drop(['match'],axis=1).rename(columns = {'level_0':'id'})\n",
    "    \n",
    "    f2 = df['text'].str.extractall(r'(?P<date>(?P<day>\\W?\\d\\d\\W?)\\W(?P<month>\\W?Jan\\W?|\\W?Feb\\W?|\\W?Mar\\W?|\\W?Apr\\W?|\\W?May\\W?|\\W?Jun\\W?|\\W?Jul\\W?|\\W?Aug\\W?|\\W?Sep\\W?|\\W?Oct\\W?|\\W?Nov\\W?|\\W?Dec\\W?)\\W(?P<year>\\W?[12]\\d{3}\\W?))')\n",
    "    f2['day'] = f2['day'].str.replace('[\\W]','')\n",
    "    f2['month'] = f2['month'].str.replace('[\\W]','')\n",
    "    f2['year'] = f2['year'].str.replace('[\\W]','')\n",
    "    f2['day'] = f2['day'].apply(lambda x: x.strip())\n",
    "    f2['month'] = f2['month'].apply(lambda x: x.strip())\n",
    "    f2['year'] = f2['year'].apply(lambda x: x.strip())\n",
    "    f2['month'] = f2['month'].map(month1)\n",
    "    f2['data2'] = f2['year']+'-'+f2['month']+'-'+f2['day']\n",
    "    f2 = f2.reset_index(level=[0,1]).drop(['match','date'],axis=1).rename(columns = {'level_0':'id'})\n",
    "    \n",
    "    f3 = df['text'].str.extractall(r'(?P<date>(?P<month>\\W?Jan\\W?|\\W?Feb\\W?|\\W?Mar\\W?|\\W?Apr\\W?|\\W?May\\W?|\\W?Jun\\W?|\\W?Jul\\W?|\\W?Aug\\W?|\\W?Sep\\W?|\\W?Oct\\W?|\\W?Nov\\W?|\\W?Dec\\W?)\\W(?P<day>\\W?\\d\\d\\W?)\\W(?P<year>\\W?[12]\\d{3}\\W?))')\n",
    "    f3['day'] = f3['day'].str.replace('[\\W]','')\n",
    "    f3['month'] = f3['month'].str.replace('[\\W]','')\n",
    "    f3['year'] = f3['year'].str.replace('[\\W]','')\n",
    "    f3['day'] = f3['day'].apply(lambda x: x.strip())\n",
    "    f3['month'] = f3['month'].apply(lambda x: x.strip())\n",
    "    f3['year'] = f3['year'].apply(lambda x: x.strip())\n",
    "    f3['month'] = f3['month'].map(month1)\n",
    "    f3['data3'] = f3['year']+'-'+f3['month']+'-'+f3['day']\n",
    "    f3 = f3.reset_index(level=[0,1]).drop(['match','date'],axis=1).rename(columns = {'level_0':'id'})\n",
    "    \n",
    "    f4 = df['text'].str.extractall(r'(?P<date>(?P<month>\\W?Jan\\W?|\\W?Feb\\W?|\\W?Mar\\W?|\\W?Apr\\W?|\\W?May\\W?|\\W?Jun\\W?|\\W?Jul\\W?|\\W?Aug\\W?|\\W?Sep\\W?|\\W?Oct\\W?|\\W?Nov\\W?|\\W?Dec\\W?)\\W(?P<year>\\W?[12]\\d{3}\\W?))')\n",
    "    f4['month'] = f4['month'].str.replace('[\\W]','')\n",
    "    f4['year'] = f4['year'].str.replace('[\\W]','')\n",
    "    f4['month'] = f4['month'].apply(lambda x: x.strip())\n",
    "    f4['year'] = f4['year'].apply(lambda x: x.strip())\n",
    "    f4['day'] = '01'\n",
    "    f4['month'] = f4['month'].map(month1)\n",
    "    f4['data4'] = f4['year']+'-'+f4['month']+'-'+f4['day']\n",
    "    f4 = f4.reset_index(level=[0,1]).drop(['match','date'],axis=1).rename(columns = {'level_0':'id'})\n",
    "    \n",
    "    f5 = df['text'].str.extractall(r'(?P<date>(?P<month>\\W?January\\W?|\\W?February\\W?|\\W?March\\W?|\\W?April\\W?|\\W?May\\W?|\\W?June\\W?|\\W?July\\W?|\\W?August\\W?|\\W?September\\W?|\\W?October\\W?|\\W?November\\W?|\\W?December\\W?)\\W(?P<day>\\W?\\d\\d\\W?)\\W(?P<year>\\W?[12]\\d{3}\\W?))')\n",
    "    f5['day'] = f5['day'].str.replace('[\\W]','')\n",
    "    f5['month'] = f5['month'].str.replace('[\\W]','')\n",
    "    f5['year'] = f5['year'].str.replace('[\\W]','')\n",
    "    f5['day'] = f5['day'].apply(lambda x: x.strip())\n",
    "    f5['month'] = f5['month'].apply(lambda x: x.strip())\n",
    "    f5['year'] = f5['year'].apply(lambda x: x.strip())\n",
    "    f5['month'] = f5['month'].map(month2)\n",
    "    f5['data5'] = f5['year']+'-'+f5['month']+'-'+f5['day']\n",
    "    f5 = f5.reset_index(level=[0,1]).drop(['match','date'],axis=1).rename(columns = {'level_0':'id'})\n",
    "    \n",
    "    f6 = df['text'].str.extractall(r'(?P<date>(?P<month>\\W?January\\W?|\\W?February\\W?|\\W?March\\W?|\\W?April\\W?|\\W?May\\W?|\\W?June\\W?|\\W?July\\W?|\\W?August\\W?|\\W?September\\W?|\\W?October\\W?|\\W?November\\W?|\\W?December\\W?)\\W(?P<year>\\W?[12]\\d{3}\\W?))')\n",
    "    f6['month'] = f6['month'].str.replace('[\\W]','')\n",
    "    f6['year'] = f6['year'].str.replace('[\\W]','')\n",
    "    f6['month'] = f6['month'].apply(lambda x: x.strip())\n",
    "    f6['year'] = f6['year'].apply(lambda x: x.strip())\n",
    "    f6['month'] = f6['month'].map(month2)\n",
    "    f6['day'] = '01'\n",
    "    f6['data6'] = f6['year']+'-'+f6['month']+'-'+f6['day']\n",
    "    f6 = f6.reset_index(level=[0,1]).drop(['match','date'],axis=1).rename(columns = {'level_0':'id'})\n",
    "    \n",
    "    f7 = df['text'].str.extractall(r'(?P<date>(?P<day>\\W?\\d\\d\\W?)\\W(?P<month>\\W?January\\W?|\\W?February\\W?|\\W?March\\W?|\\W?April\\W?|\\W?May\\W?|\\W?June\\W?|\\W?July\\W?|\\W?August\\W?|\\W?September\\W?|\\W?October\\W?|\\W?November\\W?|\\W?December\\W?)\\W(?P<year>\\W?[12]\\d{3}\\W?))')\n",
    "    f7['day'] = f7['day'].str.replace('[\\W]','')\n",
    "    f7['month'] = f7['month'].str.replace('[\\W]','')\n",
    "    f7['year'] = f7['year'].str.replace('[\\W]','')\n",
    "    f7['day'] = f7['day'].apply(lambda x: x.strip())\n",
    "    f7['month'] = f7['month'].apply(lambda x: x.strip())\n",
    "    f7['year'] = f7['year'].apply(lambda x: x.strip())\n",
    "    f7['month'] = f7['month'].map(month2)\n",
    "    f7['data7'] = f7['year']+'-'+f7['month']+'-'+f7['day']\n",
    "    f7 = f7.reset_index(level=[0,1]).drop(['match','date'],axis=1).rename(columns = {'level_0':'id'})\n",
    "    \n",
    "    f8 = df['text'].str.extractall(r'(?P<year>[a-zA-Z][12]\\d{3}[a-zA-Z]?)')\n",
    "    f8['year']= f8['year'].str.replace('[^0-9]','')\n",
    "    f8['year'] = f8['year'].apply(lambda x: x.strip())\n",
    "    f8['month'] = '01'\n",
    "    f8['day'] = '01'\n",
    "    f8['data8'] = f8['year']+'-'+f8['month']+'-'+f8['day']\n",
    "    f8 = f8.reset_index(level=[0,1]).drop(['match'],axis=1).rename(columns = {'level_0':'id'})\n",
    "    \n",
    "    f9 = df['text'].str.extractall(r'(?P<date>(?P<month>\\W?[a-zA-Z]?\\d?\\d)[-/](?P<day>\\d?\\d)[-/](?P<year>[12]\\d{3}\\W?[a-zA-Z]?))')\n",
    "    f9['day'] = f9['day'].str.replace('[^0-9]','')\n",
    "    f9['month'] = f9['month'].str.replace('[^0-9]','')\n",
    "    f9['year'] = f9['year'].str.replace('[^0-9]','')\n",
    "    f9['day'] = f9['day'].apply(lambda x: x.strip())\n",
    "    f9['month'] = f9['month'].apply(lambda x: x.strip())\n",
    "    f9['year'] = f9['year'].apply(lambda x: x.strip())\n",
    "    f9['day'] = f9['day'].astype('int').map('{:02}'.format)\n",
    "    f9['month'] = f9['month'].astype('int').map('{:02}'.format)\n",
    "    f9['data9'] = f9['year']+'-'+f9['month']+'-'+f9['day']\n",
    "    f9 = f9.reset_index(level=[0,1]).drop(['match','date'],axis=1).rename(columns = {'level_0':'id'})\n",
    "\n",
    "    f10 = df['text'].str.extractall(r'(?P<date>(?P<month>\\W?[a-zA-Z]?\\d?\\d)[-/](?P<day>\\d?\\d)[-/](?P<year>\\d{2}\\W?[a-zA-Z]?))')\n",
    "    f10['day'] = f10['day'].str.replace('[^0-9]','')\n",
    "    f10['month'] = f10['month'].str.replace('[^0-9]','')\n",
    "    f10['year'] = f10['year'].str.replace('[^0-9]','')\n",
    "    f10['day'] = f10['day'].apply(lambda x: x.strip())\n",
    "    f10['month'] = f10['month'].apply(lambda x: x.strip())\n",
    "    f10['year'] = f10['year'].apply(lambda x: x.strip())\n",
    "    f10['day'] = f10['day'].astype('int').map('{:02}'.format)\n",
    "    f10['month'] = f10['month'].astype('int').map('{:02}'.format)\n",
    "    f10['data10'] = '19'+f10['year']+'-'+f10['month']+'-'+f10['day']\n",
    "    f10 = f10.reset_index(level=[0,1]).drop(['match','date'],axis=1).rename(columns = {'level_0':'id'})\n",
    "\n",
    "    f11 = df['text'].str.extractall(r'(?P<date>(?P<month>[^/]\\d?\\d)[-/](?P<year>[1-2]\\d{3}\\W))')\n",
    "    f11['month'] = f11['month'].str.replace('[^0-9]','')\n",
    "    f11['year'] = f11['year'].str.replace('[^0-9]','')\n",
    "    f11['month'] = f11['month'].apply(lambda x: x.strip())\n",
    "    f11['year'] = f11['year'].apply(lambda x: x.strip())\n",
    "    f11['month'] = f11['month'].astype('int').map('{:02}'.format)\n",
    "    f11['day'] = '01'\n",
    "    f11['data11'] = f11['year']+'-'+f11['month']+'-'+f11['day']\n",
    "    f11 = f11.reset_index(level=[0,1]).drop(['match','date'],axis=1).rename(columns = {'level_0':'id'})\n",
    "\n",
    "    f1.drop(['day','month','year'],axis=1,inplace=True)\n",
    "    f2.drop(['day','month','year'],axis=1,inplace=True)\n",
    "    f3.drop(['day','month','year'],axis=1,inplace=True)\n",
    "    f4.drop(['day','month','year'],axis=1,inplace=True)\n",
    "    f5.drop(['day','month','year'],axis=1,inplace=True)\n",
    "    f6.drop(['day','month','year'],axis=1,inplace=True)\n",
    "    f7.drop(['day','month','year'],axis=1,inplace=True)\n",
    "    f8.drop(['day','month','year'],axis=1,inplace=True)\n",
    "    f9.drop(['day','month','year'],axis=1,inplace=True)\n",
    "    f10.drop(['day','month','year'],axis=1,inplace=True)\n",
    "    f11.drop(['day','month','year'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "    data = f1.merge(f2,how='outer',left_on='id',right_on = 'id', \n",
    "                sort=True).merge(f3,how='outer',left_on='id',right_on = 'id', \n",
    "                sort=True).merge(f4,how='outer',left_on='id',right_on = 'id', \n",
    "                sort=True).merge(f5,how='outer',left_on='id',right_on = 'id', \n",
    "                sort=True).merge(f6,how='outer',left_on='id',right_on = 'id', \n",
    "                sort=True).merge(f7,how='outer',left_on='id',right_on = 'id', \n",
    "                sort=True).merge(f8,how='outer',left_on='id',right_on = 'id', \n",
    "                sort=True).merge(f9,how='outer',left_on='id',right_on = 'id', \n",
    "                sort=True).merge(f10,how='outer',left_on='id',right_on = 'id', \n",
    "                sort=True).merge(f11,how='outer',left_on='id',right_on = 'id', \n",
    "                sort=True).fillna(';')\n",
    "\n",
    "\n",
    "    data['data'] = data['data1']+'/'+data['data2']+'/'+data['data3']+'/'+data['data4']+'/'+data['data5']+'/'+data['data6']+'/'+data['data7']+'/'+data['data8']+'/'+data['data9']+'/'+data['data10']+'/'+data['data11']\n",
    "\n",
    "    data.drop(['data1','data2','data3','data4','data5','data6','data7','data8','data9','data10','data11'],axis=1,inplace=True)\n",
    "\n",
    "    data['data'] = data.data.str.replace('[^0-9-]',' ').apply(lambda x: x.strip())\n",
    "\n",
    "    data = data.join(data['data'].str.split(' ',2,expand=True)).rename(columns={0:'A',1:'B',2:'C'}).drop(['data','B','C'],axis=1)\n",
    "\n",
    "    data['id'] = data['id'].astype('int')\n",
    "    \n",
    "    all_indeces = np.arange(0,500,1)\n",
    "    total_indeces= np.concatenate((np.array(data['id']),all_indeces), axis = 0)\n",
    "    (unique, counts) = np.unique(total_indeces,return_counts = True)\n",
    "    frequencies = np.asarray((unique, counts)).T\n",
    "    table=pd.DataFrame(frequencies, columns = ['index', 'count'])\n",
    "    missing_indeces = table[table['count']==1]\n",
    "    double_counts = table[table['count']==3]\n",
    "    missing_array = np.array(missing_indeces['index'])\n",
    "    df.iloc[missing_indeces['index'],:]\n",
    "\n",
    "    f13 = df.iloc[missing_indeces['index'],:]['text'].str.extractall(r'(?P<date>(?P<month>\\d{1})/(?P<year>[1-2]\\d{3}\\W))')\n",
    "    f13['month'] = f13['month'].str.replace('[^0-9]','')\n",
    "    f13['year'] = f13['year'].str.replace('[^0-9]','')\n",
    "    f13['month'] = f13['month'].apply(lambda x: x.strip())\n",
    "    f13['year'] = f13['year'].apply(lambda x: x.strip())\n",
    "    f13['month'] = f13['month'].astype('int').map('{:02}'.format)\n",
    "    f13['day'] = '01'\n",
    "    f13['data13'] = f13['year']+'-'+f13['month']+'-'+f13['day']\n",
    "    f13 = f13.reset_index(level=[0,1]).drop(['match','date','year','day','month'],axis=1).rename(columns = {'level_0':'id'})\n",
    "\n",
    "    f14 = df.iloc[missing_indeces['index'],:]['text'].str.extractall(r'(?P<date>(?P<year>[^/][1-2]\\d{3}\\W))')\n",
    "    f14['year'] = f14['year'].str.replace('[^0-9]','')\n",
    "    f14['year'] = f14['year'].apply(lambda x: x.strip())\n",
    "    f14['day'] = '01'\n",
    "    f14['month'] = '01'\n",
    "    f14['data14'] = f14['year']+'-'+f14['month']+'-'+f14['day']\n",
    "    f14 = f14.reset_index(level=[0,1]).drop(['match','date','year','day','month'],axis=1).rename(columns = {'level_0':'id'})\n",
    "\n",
    "    month3 = {'Janaury':'01','Decemeber':'12'}\n",
    "\n",
    "    f15 = df.iloc[missing_indeces['index'],:]['text'].str.extractall(r'(?P<date>(?P<month>(Jan[a-z]+|Feb[a-z]+|Mar[a-z]+|Apr[a-z]+|May[a-z]+|Jun[a-z]+[a-z]+|Jul[a-z]+|Aug[a-z]+|Sep[a-z]+|Oct[a-z]+|Nov[a-z]+|Dec[a-z]+))\\W(?P<year>\\W?[1-2]\\d{3}))')\n",
    "    f15['month'] = f15['month'].str.replace('[\\W]','')\n",
    "    f15['year'] = f15['year'].str.replace('[\\W]','')\n",
    "    f15['month'] = f15['month'].apply(lambda x: x.strip())\n",
    "    f15['year'] = f15['year'].apply(lambda x: x.strip())\n",
    "    f15['month'] = f15['month'].map(month3)\n",
    "    f15['day'] = '01'\n",
    "    f15['data15'] = f15['year']+'-'+f15['month']+'-'+f15['day']\n",
    "    f15 = f15.reset_index(level=[0,1]).drop(['match','date',2,'month','year','day'],axis=1).rename(columns = {'level_0':'id'})\n",
    "\n",
    "    data_missing = f15.merge(f13,how='outer',left_on='id',right_on = 'id', \n",
    "                sort=True).merge(f14,how='outer',left_on='id',right_on = 'id', \n",
    "                sort=True).fillna(';')\n",
    "\n",
    "\n",
    "    data_missing['data_missing'] = data_missing['data13']+'/'+data_missing['data14']+'/'+data_missing['data15']\n",
    "\n",
    "    data_missing.drop(['data13','data14','data15'],axis=1,inplace=True)\n",
    "\n",
    "    data_missing['data_missing'] = data_missing.data_missing.str.replace('[^0-9-]',' ').apply(lambda x: x.strip())\n",
    "\n",
    "    data_missing = data_missing.join(data_missing['data_missing'].str.split(' ',1,expand=True)).rename(columns={0:'D',1:'E'})\n",
    "\n",
    "    data_missing.iloc[1,2] = data_missing.iloc[1,3]\n",
    "\n",
    "    data_missing.drop(['data_missing', 'E'],axis=1,inplace=True)\n",
    "\n",
    "    data2 = data.merge(data_missing, how = 'outer', left_on='id',right_on='id',sort=True).fillna(';')\n",
    "\n",
    "    data2['A'] = data2['A']+'/'+data2['D']\n",
    "\n",
    "    data2.drop(['D'],axis=1,inplace=True)\n",
    "\n",
    "    data2['A'] = data2.A.str.replace('[^0-9-]',' ').apply(lambda x: x.strip())\n",
    "\n",
    "    all_indeces = np.arange(0,500,1)\n",
    "    total_indeces= np.concatenate((np.array(data2['id']),all_indeces), axis = 0)\n",
    "    (unique, counts) = np.unique(total_indeces,return_counts = True)\n",
    "    frequencies = np.asarray((unique, counts)).T\n",
    "    table=pd.DataFrame(frequencies, columns = ['index', 'count'])\n",
    "    missing_indeces = table[table['count']==1]\n",
    "    double_counts = table[table['count']==3]\n",
    "    missing_array = np.array(missing_indeces['index'])\n",
    "    df.iloc[missing_indeces['index'],:]\n",
    "\n",
    "    f16 = df.iloc[missing_indeces['index'],:]['text'].str.extractall(r'(?P<date>(?P<year>[1-2]\\d{3}\\W))')\n",
    "    f16['year'] = f16['year'].str.replace('[^0-9]','')\n",
    "    f16['year'] = f16['year'].apply(lambda x: x.strip())\n",
    "    f16['day'] = '01'\n",
    "    f16['month'] = '01'\n",
    "    f16['data16'] = f16['year']+'-'+f16['month']+'-'+f16['day']\n",
    "    f16 = f16.reset_index(level=[0,1]).drop(['match','date','year','day','month'],axis=1).rename(columns = {'level_0':'id'})\n",
    "\n",
    "    data3 = data2.merge(f16, how = 'outer', left_on='id',right_on='id',sort=True).fillna(';')\n",
    "\n",
    "    data3['A'] = data3['A']+'/'+data3['data16']\n",
    "\n",
    "    data3.drop(['data16'],axis=1,inplace=True)\n",
    "\n",
    "    data3['A'] = data3.A.str.replace('[^0-9-]',' ').apply(lambda x: x.strip())\n",
    "\n",
    "    data3[data3.index != data3['id']]\n",
    "\n",
    "    data3.iloc[70:80,:]\n",
    "\n",
    "    data3.drop(73, axis=0, inplace = True)\n",
    "\n",
    "    data3 = data3.sort_values('A', ascending = True).reset_index().drop('index', axis=1)\n",
    "    \n",
    "    return pd.Series(data3['id'])\n",
    "\n",
    "date_sorter()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def date_sorter():\n",
    "    import re\n",
    "    \n",
    "    year = df['text'].str.extractall(r'(?P<year>.?[12]\\d{3}.?)')\n",
    "    year['year']= year['year'].str.replace('[^0-9]','')\n",
    "    year['year'] = year['year'].apply(lambda x: x.strip())\n",
    "    year = year.reset_index(level=1).drop('match',axis=1)\n",
    "    \n",
    "    day_month1 = df['text'].str.extractall(r'(?P<day_month1>(?P<day>\\W\\d?\\d)\\W(?P<month>\\W?Jan\\W?|\\W?Feb\\W?|\\W?Mar\\W?|\\W?Apr\\W?|\\W?May\\W?|\\W?Jun\\W?|\\W?Jul\\W?|\\W?Aug\\W?|\\W?Sep\\W?|\\W?Oct\\W?|\\W?Nov\\W?|\\W?Dec\\W?))').drop('day_month1', axis=1).drop(108, axis = 0)\n",
    "    day_month1['day'] = day_month1['day'].str.replace('[.,;:/\\)(-]','')\n",
    "    day_month1['month'] = day_month1['month'].str.replace('[.,;:/\\)(-]','')\n",
    "    day_month1['day'] = day_month1['day'].apply(lambda x: x.strip())\n",
    "    day_month1['month'] = day_month1['month'].apply(lambda x: x.strip())\n",
    "    day_month1 = day_month1.reset_index(level=1).drop('match',axis=1)\n",
    "    \n",
    "    day_month2 = df['text'].str.extractall(r'(?P<day_month2>(?P<day>\\W\\d?\\d)\\W(?P<month>\\W?January\\W?|\\W?February\\W?|\\W?March\\W?|\\W?April\\W?|\\W?June\\W?|\\W?July\\W?|\\W?August\\W?|\\W?September\\W?|\\W?October\\W?|\\W?November\\W?|\\W?December\\W?))').drop('day_month2', axis=1)\n",
    "    day_month2['day'] = day_month2['day'].str.replace('[.,;:/\\)(-]','')\n",
    "    day_month2['month'] = day_month2['month'].str.replace('[.,;:/\\)(-]','')\n",
    "    day_month2['day'] = day_month2['day'].apply(lambda x: x.strip())\n",
    "    day_month2['month'] = day_month2['month'].apply(lambda x: x.strip())\n",
    "    day_month2 = day_month2.reset_index(level=1).drop('match',axis=1)\n",
    "    \n",
    "    month_day1 = df['text'].str.extractall(r'(?P<month_day1>(?P<month>\\W?Jan\\W?|\\W?Feb\\W?|\\W?Mar\\W?|\\W?Apr\\W?|\\W?May\\W?|\\W?Jun\\W?|\\W?Jul\\W?|\\W?Aug\\W?|\\W?Sep\\W?|\\W?Oct\\W?|\\W?Nov\\W?|\\W?Dec\\W?)\\W(?P<day>\\d?\\d\\W))').drop('month_day1', axis=1)\n",
    "    month_day1['day'] = month_day1['day'].str.replace('[.,;:/\\)(-]','')\n",
    "    month_day1['month'] = month_day1['month'].str.replace('[.,;:/\\)(-]','')\n",
    "    month_day1['day'] = month_day1['day'].apply(lambda x: x.strip())\n",
    "    month_day1['month'] = month_day1['month'].apply(lambda x: x.strip())\n",
    "    month_day1 = month_day1.reset_index(level=1).drop('match',axis=1)\n",
    "    \n",
    "    month_day2 =df['text'].str.extractall(r'(?P<month_day2>(?P<month>\\W?January\\W?|\\W?February\\W?|\\W?March\\W?|\\W?April\\W?|\\W?June\\W?|\\W?July\\W?|\\W?August\\W?|\\W?September\\W?|\\W?October\\W?|\\W?November\\W?|\\W?December\\W?)\\W(?P<day>\\W\\d?\\d))').drop('month_day2', axis=1)\n",
    "    month_day2['day'] = month_day2['day'].str.replace('[.,;:/\\)(-]','')\n",
    "    month_day2['month'] = month_day2['month'].str.replace('[.,;:/\\)(-]','')\n",
    "    month_day2['day'] = month_day2['day'].apply(lambda x: x.strip())\n",
    "    month_day2['month'] = month_day2['month'].apply(lambda x: x.strip())\n",
    "    month_day2 = month_day2.reset_index(level=1).drop('match',axis=1)\n",
    "    \n",
    "    day_month_year1 = df['text'].str.extractall(r'(?P<day_month_year>(?P<month>\\d?\\d)[-/]{1}(?P<day>\\d?\\d)[-/]{1}(?P<year>[12]\\d{3}))').drop('day_month_year', axis=1)\n",
    "    day_month_year1['day'] = day_month_year1['day'].str.replace('[^0-9]','')\n",
    "    day_month_year1['month'] = day_month_year1['month'].str.replace('[^0-9]','')\n",
    "    day_month_year1['year'] = day_month_year1['year'].str.replace('[^0-9]','')\n",
    "    day_month_year1['day'] = day_month_year1['day'].apply(lambda x: x.strip())\n",
    "    day_month_year1['month'] = day_month_year1['month'].apply(lambda x: x.strip())\n",
    "    day_month_year1['year'] = day_month_year1['year'].apply(lambda x: x.strip())\n",
    "    day_month_year1 = day_month_year1.reset_index(level=1).drop('match',axis=1)\n",
    "    \n",
    "    day_month_year2 = df['text'].str.extractall(r'(?P<day_month_year>(?P<month>\\d?\\d)[-/]{1}(?P<day>\\d?\\d)[-/]{1}(?P<year>\\d{2}))').drop('day_month_year', axis=1)\n",
    "    day_month_year2['day'] = day_month_year2['day'].str.replace('[^0-9]','')\n",
    "    day_month_year2['month'] = day_month_year2['month'].str.replace('[^0-9]','')\n",
    "    day_month_year2['year'] = day_month_year2['year'].str.replace('[^0-9]','')\n",
    "    day_month_year2['day'] = day_month_year2['day'].apply(lambda x: x.strip())\n",
    "    day_month_year2['month'] = day_month_year2['month'].apply(lambda x: x.strip())\n",
    "    day_month_year2['year'] = day_month_year2['year'].apply(lambda x: x.strip())\n",
    "    day_month_year2 = day_month_year2.reset_index(level=1).drop('match',axis=1)\n",
    "   \n",
    "    month_year = df['text'].str.extractall(r'(?P<month_year>(?P<month>[^\\d/]\\d?\\d)/(?P<year>[12]\\d{3}\\W))').drop('month_year', axis=1)\n",
    "    month_year['month'] = month_year['month'].str.replace('[^0-9]','')\n",
    "    month_year['year'] = month_year['year'].str.replace('[^0-9]','')\n",
    "    month_year['month'] = month_year['month'].apply(lambda x: x.strip())\n",
    "    month_year['year'] = month_year['year'].apply(lambda x: x.strip())\n",
    "    month_year = month_year.reset_index(level=1).drop('match',axis=1)\n",
    "    \n",
    "    month1 = {'Jan':'01','Feb':'02','Mar':'03','Apr':'04','May':'05','Jun':'06',\n",
    "                 'Jul':'07','Aug':'08','Sep':'09','Oct':'10','Nov':'11','Dec':'12'}\n",
    "    \n",
    "    month2 = {'January':'01','February':'02','March':'03','April':'04','May':'05','June':'06',\n",
    "                 'July':'07','August':'08','September':'09','October':'10','November':'11','December':'12'}\n",
    "    \n",
    "    date1 = day_month1.merge(year, how ='inner', left_index = True, right_index = True)\n",
    "    date2 = day_month2.merge(year, how ='inner', left_index = True, right_index = True)\n",
    "    date3 = month_day1.merge(year, how ='inner', left_index = True, right_index = True)\n",
    "    date4 = month_day2.merge(year, how ='inner', left_index = True, right_index = True)\n",
    "    month_year['day'] = '01'\n",
    "    year['day'] = '01'\n",
    "    year['month'] = '01'\n",
    "    \n",
    "    date1['month'] = date1['month'].map(month1)\n",
    "    date2['month'] = date2['month'].map(month2)\n",
    "    date3['month'] = date3['month'].map(month1)\n",
    "    date4['month'] = date4['month'].map(month2)\n",
    "    \n",
    "    date1 = date1.astype('int')\n",
    "    date2 = date2.astype('int')\n",
    "    date3 = date3.astype('int')\n",
    "    date4 = date4.astype('int')\n",
    "    month_year = month_year.astype('int')\n",
    "    day_month_year1 = day_month_year1.astype('int')\n",
    "    day_month_year2 = day_month_year2.astype('int')\n",
    "    year = year.astype('int')\n",
    "\n",
    "    date1[\"month\"] = date1.month.map(\"{:02}\".format)\n",
    "    date2[\"month\"] = date2.month.map(\"{:02}\".format)\n",
    "    date3[\"month\"] = date3.month.map(\"{:02}\".format)\n",
    "    date4[\"month\"] = date4.month.map(\"{:02}\".format)\n",
    "    month_year[\"month\"] = month_year.month.map(\"{:02}\".format)\n",
    "    day_month_year1[\"month\"] = day_month_year1.month.map(\"{:02}\".format)\n",
    "    day_month_year2[\"month\"] = day_month_year2.month.map(\"{:02}\".format)\n",
    "    year['month'] = year.month.map(\"{:02}\".format)\n",
    "    \n",
    "    date1[\"day\"] = date1.day.map(\"{:02}\".format)\n",
    "    date2[\"day\"] = date2.day.map(\"{:02}\".format)\n",
    "    date3[\"day\"] = date3.day.map(\"{:02}\".format)\n",
    "    date4[\"day\"] = date4.day.map(\"{:02}\".format)\n",
    "    day_month_year1[\"day\"] = day_month_year1.day.map(\"{:02}\".format)\n",
    "    day_month_year2[\"day\"] = day_month_year2.day.map(\"{:02}\".format)\n",
    "    year['day'] = year.day.map(\"{:02}\".format)\n",
    "    month_year[\"day\"] = month_year.day.map(\"{:02}\".format)\n",
    "    \n",
    "    date1 = date1.astype('str')\n",
    "    date2 = date2.astype('str')\n",
    "    date3 = date3.astype('str')\n",
    "    date4 = date4.astype('str')\n",
    "    month_year = month_year.astype('str')\n",
    "    day_month_year1 = day_month_year1.astype('str')\n",
    "    day_month_year2 = day_month_year2.astype('str')\n",
    "    year = year.astype('str')\n",
    "    \n",
    "    \n",
    "    date1['date'] = date1['year']+'/'+date1['month']+'/'+date1['day']\n",
    "    date2['date'] = date2['year']+'/'+date2['month']+'/'+date2['day']\n",
    "    date3['date'] = date3['year']+'/'+date3['month']+'/'+date3['day']\n",
    "    date4['date'] = date4['year']+'/'+date4['month']+'/'+date4['day']\n",
    "    month_year['date'] = month_year['year']+'/'+month_year['month']+'/'+month_year['day']\n",
    "    day_month_year1['date'] = day_month_year1['year']+'/'+day_month_year1['month']+'/'+day_month_year1['day']\n",
    "    day_month_year2['date'] = '19'+day_month_year2['year']+'/'+day_month_year2['month']+'/'+day_month_year2['day']\n",
    "    year['date'] = year['year']+'/'+year['month']+'/'+year['day']\n",
    "    \n",
    "    date1 = date1.drop(['month', 'day','year'], axis=1).reset_index().rename(columns={'date':'date1'})\n",
    "    date2 = date2.drop(['month', 'day','year'], axis=1).reset_index().rename(columns={'date':'date2'})\n",
    "    date3 = date3.drop(['month', 'day','year'], axis=1).reset_index().rename(columns={'date':'date3'})\n",
    "    date4 = date4.drop(['month', 'day','year'], axis=1).reset_index().rename(columns={'date':'date4'})\n",
    "    month_year = month_year.drop(['month', 'day','year'], axis=1).reset_index().rename(columns={'date':'date5'})\n",
    "    day_month_year1 = day_month_year1.drop(['month', 'day','year'], axis=1).reset_index().rename(columns={'date':'date6'})\n",
    "    day_month_year2 = day_month_year2.drop(['month', 'day','year'], axis=1).reset_index().rename(columns={'date':'date7'})\n",
    "    year = year.drop(['month', 'day','year'], axis=1).reset_index().rename(columns={'date':'date8'})\n",
    "    \n",
    "    dates =  date1.merge(date2,how='outer',left_on='index',right_on='index', sort = True\n",
    "                        ).merge(date3,how='outer',left_on='index',right_on='index', sort =True\n",
    "                               ).merge(date4,how='outer',left_on='index',right_on='index', sort =True\n",
    "                                      ).merge(month_year,how='outer',left_on='index',right_on='index', sort =True\n",
    "                                             ).merge(day_month_year1,how='outer',left_on='index',right_on='index', sort =True\n",
    "                                                    ).merge(day_month_year2,how='outer',left_on='index',right_on='index', sort =True\n",
    "                                                           ).merge(year, how = 'outer', left_on='index', right_on = 'index', sort =True\n",
    "                                                                  )\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    dates = dates.fillna('a').astype('str')  \n",
    "    \n",
    "    dates['date1'] = dates['date1']+';'+dates['date2']+';'+dates['date3']+';'+dates['date4']+';'+dates['date5']+';'+dates['date6']+';'+dates['date7']+';'+dates['date8'] \n",
    "    \n",
    "    dates.drop(['date2','date3','date4','date5','date6','date7','date8'],axis=1, inplace = True)\n",
    "    \n",
    "    dates['date1'] = dates['date1'].str.replace('[a;]',' ')\n",
    "    \n",
    "    dates['date1'] = dates['date1'].str.strip()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    dates['index'] = dates['index'].astype('int')\n",
    "    \n",
    "    #all_indeces = np.arange(0,500,1)\n",
    "    #total= np.concatenate((np.array(dates['index']),all_indeces), axis = 0)\n",
    "    #(unique, counts) = np.unique(total,return_counts = True)\n",
    "    #frequencies = np.asarray((unique, counts)).T\n",
    "    #tableau=pd.DataFrame(frequencies, columns = ['index', 'count'])\n",
    "    #missing = tableau[tableau['count']==1]\n",
    "    #double_count = tableau[tableau['count']==3]\n",
    "    #missing_array = np.array(missing['index'])\n",
    "    #df.iloc[missing['index'],:]\n",
    "    #df.iloc[double_count['index'],:]\n",
    "    \n",
    "    dates[dates.index != dates['index']]\n",
    "    dates.iloc[70:80,:]\n",
    "    \n",
    "    dates.drop(73, axis=0, inplace = True)\n",
    "    \n",
    "    data = dates.join(dates['date1'].str.split(' ', 2, expand=True).rename(columns={0:'A', 1:'B',2:'C'})).drop(['B','C','date1'], axis=1).sort_values('A', ascending = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return pd.Series(data['index'])\n",
    "\n",
    "date_sorter()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "LvcWI",
   "launcher_item_id": "krne9",
   "part_id": "Mkp1I"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
